{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hg4iowmJL2Sf"
      },
      "source": [
        "> ### Note on Labs and Assignments:\n",
        ">\n",
        "> ðŸ”§ Look for the **wrench emoji** ðŸ”§ â€” it highlights where you're expected to take action!\n",
        ">\n",
        "> These sections are graded and are not optional.\n",
        ">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzjjuIUALoXZ"
      },
      "source": [
        "# IS 4487 Lab 12: Naive Bayes, SVM, and Neural Networks\n",
        "\n",
        "## Outline\n",
        "\n",
        "- Apply Naive Bayes to a binary classification problem  \n",
        "- Train a Support Vector Machine (SVM) model  \n",
        "- Explore a simple Neural Network for classification  \n",
        "- Evaluate models using accuracy and classification reports  \n",
        "- Compare performance and discuss model selection  \n",
        "\n",
        "In this lab, weâ€™ll explore three advanced classification models â€” **Naive Bayes**, **Support Vector Machines (SVM)**, and **Neural Networks** â€” to predict **high engagement** in Super Bowl YouTube ads based on video metadata and features.\n",
        "\n",
        "Weâ€™ll use the **Super Bowl Ads dataset** and continue developing your skills in selecting and evaluating machine learning models.\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/vandanara/UofUtah_IS4487/blob/main/Labs/lab_12_bayes_svm_neural.ipynb\" target=\"_parent\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxngoVZiMGrf"
      },
      "source": [
        "## Data Description\n",
        "\n",
        "The dataset for this lab consists of **YouTube metadata and thematic features** of Super Bowl commercials, originally sourced from [TidyTuesday (March 2, 2021)](https://github.com/rfordatascience/tidytuesday/blob/master/data/2021/2021-03-02/youtube.csv).\n",
        "\n",
        "Each row represents one Super Bowl ad, and the dataset includes both **video characteristics** and **performance metrics**, such as view counts and like counts.\n",
        "\n",
        "Below are key variables we'll work with:\n",
        "\n",
        "| Variable                 | Type        | Description                                                                 |\n",
        "|--------------------------|-------------|------------------------------------------------------------------------------|\n",
        "| `year`                   | numeric     | Year the ad aired during the Super Bowl                                     |\n",
        "| `brand`                  | categorical | Advertiser brand (e.g., Doritos, Budweiser)                                 |\n",
        "| `funny`                  | binary      | Indicates if the ad uses humor (1 = yes, 0 = no)                            |\n",
        "| `show_product_quickly`  | binary      | Product is shown early in the video (1 = yes)                               |\n",
        "| `patriotic`              | binary      | Includes patriotic content (1 = yes)                                        |\n",
        "| `celebrity`              | binary      | Features a celebrity (1 = yes)                                              |\n",
        "| `danger`                 | binary      | Involves danger or risk (1 = yes)                                           |\n",
        "| `animals`                | binary      | Includes animals (1 = yes)                                                  |\n",
        "| `use_sex`                | binary      | Includes sexual content or appeal (1 = yes)                                 |\n",
        "| `view_count`             | numeric     | Total number of YouTube views for the ad                                    |\n",
        "| `like_count`             | numeric     | Number of likes the ad received on YouTube                                  |\n",
        "| `dislike_count`          | numeric     | Number of dislikes                                                          |\n",
        "| `favorite_count`         | numeric     | Number of favorites (often unused in modern YouTube data)                   |\n",
        "| `comment_count`          | numeric     | Number of comments                                                          |\n",
        "| `high_engagement`        | binary      | Derived variable: 1 if `like_count` above median, 0 otherwise (our target)  |\n",
        "\n",
        "### Why this dataset?\n",
        "\n",
        "This dataset is perfect for:\n",
        "- **Classification tasks**: Predict whether an ad achieved high engagement.\n",
        "- **Marketing insights**: Identify which ad traits (e.g., humor, celebrities) drive viewer responses.\n",
        "- **Model interpretation**: Practice with models suited for both binary and numerical data.\n",
        "\n",
        "Throughout the lab, we'll focus on the `high_engagement` variable as the **target** and explore how ad content features relate to audience engagement.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_g0i9hkMTBi"
      },
      "source": [
        "## Part 1: Load and Clean the Data\n",
        "\n",
        "In this first step, we will:\n",
        "- Load the dataset from GitHub url\n",
        "- Clean and preprocess it by removing irrelevant columns.\n",
        "- Engineer a binary target variable for \"high engagement\" (above median likes).\n",
        "\n",
        "This will ensure the data is in a format that can be used effectively for modeling.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fccJdJAFIwVy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "28f4430c-d72c-4a16-e292-a1b6ba11cdcf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   view_count  like_count  high_engagement  funny  show_product_quickly  \\\n",
              "0    173929.0      1233.0                1      0                     0   \n",
              "1     47752.0       485.0                1      1                     1   \n",
              "2    142310.0       129.0                0      1                     0   \n",
              "3       198.0         2.0                0      0                     1   \n",
              "4     13741.0        20.0                0      1                     1   \n",
              "\n",
              "   patriotic  celebrity  danger  animals  use_sex  \n",
              "0          0          0       0        0        0  \n",
              "1          0          1       1        0        0  \n",
              "2          0          0       1        1        0  \n",
              "3          0          0       0        0        0  \n",
              "4          0          0       1        1        1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3faf2a72-34ce-4de7-8324-d616b068e560\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>view_count</th>\n",
              "      <th>like_count</th>\n",
              "      <th>high_engagement</th>\n",
              "      <th>funny</th>\n",
              "      <th>show_product_quickly</th>\n",
              "      <th>patriotic</th>\n",
              "      <th>celebrity</th>\n",
              "      <th>danger</th>\n",
              "      <th>animals</th>\n",
              "      <th>use_sex</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>173929.0</td>\n",
              "      <td>1233.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>47752.0</td>\n",
              "      <td>485.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>142310.0</td>\n",
              "      <td>129.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>198.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13741.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3faf2a72-34ce-4de7-8324-d616b068e560')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3faf2a72-34ce-4de7-8324-d616b068e560 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3faf2a72-34ce-4de7-8324-d616b068e560');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-97b33dcf-3b03-4f69-b9be-0ebccfe2bd7f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-97b33dcf-3b03-4f69-b9be-0ebccfe2bd7f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-97b33dcf-3b03-4f69-b9be-0ebccfe2bd7f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"youtube[['view_count', 'like_count', 'high_engagement'] + logical_columns]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"view_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 78112.61733868608,\n        \"min\": 198.0,\n        \"max\": 173929.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          47752.0,\n          13741.0,\n          142310.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"like_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 518.1521977180064,\n        \"min\": 2.0,\n        \"max\": 1233.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          485.0,\n          20.0,\n          129.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"high_engagement\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"funny\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"show_product_quickly\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"patriotic\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"celebrity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"danger\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"animals\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"use_sex\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load dataset\n",
        "url = 'https://raw.githubusercontent.com/vandanara/UofUtah_IS4487/refs/heads/main/DataSets/youtube.csv'\n",
        "youtube = pd.read_csv(url)\n",
        "\n",
        "# Drop irrelevant or complex API columns\n",
        "youtube = youtube.drop(columns=[\n",
        "    'superbowl_ads_dot_com_url', 'youtube_url', 'id', 'kind', 'etag',\n",
        "    'published_at', 'title', 'description', 'thumbnail', 'channel_title'\n",
        "])\n",
        "\n",
        "# Convert logical (boolean) columns to integers for modeling\n",
        "logical_columns = ['funny', 'show_product_quickly', 'patriotic', 'celebrity', 'danger', 'animals', 'use_sex']\n",
        "youtube[logical_columns] = youtube[logical_columns].astype(int)\n",
        "\n",
        "# Drop rows with missing like_count\n",
        "youtube = youtube.dropna(subset=['like_count', 'view_count'])\n",
        "\n",
        "# Create target: high_engagement\n",
        "median_likes = youtube['like_count'].median()\n",
        "youtube['high_engagement'] = (youtube['like_count'] > median_likes).astype(int)\n",
        "\n",
        "\n",
        "# Final feature set\n",
        "youtube[['view_count', 'like_count', 'high_engagement'] + logical_columns].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYk0ijucMblE"
      },
      "source": [
        "## Part 2: Naive Bayes Classifier\n",
        "\n",
        "Naive Bayes is a **probabilistic model** based on Bayes' Theorem. It assumes **independence** between features, which isn't always trueâ€”but it works surprisingly well for text and binary features.\n",
        "\n",
        "We'll use the boolean ad features (like `funny`, `celebrity`, etc.) to predict whether the video had high engagement.\n",
        "\n",
        "Ask Yourself:\n",
        "- Do you think any of these features (like \"celebrity\") might strongly influence likes?\n",
        "- How might the independence assumption affect the predictions?\n",
        "\n",
        "Let's train the model and evaluate performance using a **confusion matrix** and **classification report**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2puWt9tdMloI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a175cb4-239a-4aee-e5e8-a7e21f5b5f24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            " [[15 12]\n",
            " [ 8 10]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.56      0.60        27\n",
            "           1       0.45      0.56      0.50        18\n",
            "\n",
            "    accuracy                           0.56        45\n",
            "   macro avg       0.55      0.56      0.55        45\n",
            "weighted avg       0.57      0.56      0.56        45\n",
            "\n",
            "Accuracy: 0.5555555555555556\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Features and labels\n",
        "X = youtube[logical_columns]\n",
        "y = youtube['high_engagement']\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Fit model\n",
        "nb_model = BernoulliNB()\n",
        "nb_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred_nb = nb_model.predict(X_test)\n",
        "\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_nb))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_nb))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_nb))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjFaYMDQMon8"
      },
      "source": [
        "### ðŸ”§ Try It Yourself â€” Part 2\n",
        "\n",
        "1. **Change the test size** to `0.2`. How does this affect accuracy?  \n",
        "   > Update `train_test_split(test_size=0.2)` and rerun the model.\n",
        "\n",
        "2. **Remove `celebrity` and `funny` features** from X. Rerun the model and check performance.  \n",
        "   > Modify:  \n",
        "   `X = youtube[['show_product_quickly', 'patriotic', 'danger', 'animals', 'use_sex']]`\n",
        "\n",
        "### In Your Response:\n",
        "\n",
        "1. Which model setup performed best? Why might that be?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8vK-HTs0vFgn"
      },
      "outputs": [],
      "source": [
        "# ðŸ”§ Add code here\n",
        "X = youtube[['show_product_quickly', 'patriotic', 'danger', 'animals', 'use_sex']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YczZyD_kvFVH"
      },
      "source": [
        "### âœï¸ Your Response: ðŸ”§\n",
        "1. The second model setup worked worse than the first model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5Fds3ucNQBZ"
      },
      "source": [
        "## Part 3: Support Vector Machine (SVM)\n",
        "\n",
        "### What you're going to do:\n",
        "Use a **Support Vector Machine** with an RBF kernel to classify ads, using both binary and numeric features.\n",
        "\n",
        "### Why this matters:\n",
        "SVMs are powerful for high-dimensional data and can find optimal decision boundaries. They are also common in fraud detection and image recognition.\n",
        "\n",
        "### Regularization Parameter (C):\n",
        "\n",
        "- In the model parameters, you will see `C`, which controls the trade-off between achieving a low training error and a low testing error (generalization).\n",
        "\n",
        "- A large `C` value (e.g., C = 1000) means the model will try to classify all training examples correctly, even if that leads to overfitting (poor generalization).\n",
        "\n",
        "- A small `C` value (e.g., C = 0.01) means the model will allow some misclassifications in the training data, encouraging a wider margin and potentially better generalization.\n",
        "\n",
        "### What to notice:\n",
        "- How does scaling the data affect performance?\n",
        "- What happens when you change the kernel or regularization?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "XPEmMcuQN3xv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78bf1644-ef4b-4c79-9b1f-57acd0ad8bbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            " [[20 18]\n",
            " [17 13]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.53      0.53        38\n",
            "           1       0.42      0.43      0.43        30\n",
            "\n",
            "    accuracy                           0.49        68\n",
            "   macro avg       0.48      0.48      0.48        68\n",
            "weighted avg       0.49      0.49      0.49        68\n",
            "\n",
            "Accuracy: 0.4852941176470588\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Add numeric feature\n",
        "X_full = youtube[logical_columns + ['view_count']]\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_full)\n",
        "\n",
        "# Split\n",
        "X_train_svm, X_test_svm, y_train_svm, y_test_svm = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train SVM\n",
        "svm_model = SVC(kernel='linear', C=1.0, gamma='scale')\n",
        "svm_model.fit(X_train_svm, y_train_svm)\n",
        "\n",
        "# Predict\n",
        "y_pred_svm = svm_model.predict(X_test_svm)\n",
        "\n",
        "# Evaluate\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_svm, y_pred_svm))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test_svm, y_pred_svm))\n",
        "print(\"Accuracy:\", accuracy_score(y_test_svm, y_pred_svm))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_QzP-f_N6kK"
      },
      "source": [
        "### ðŸ”§ Try It Yourself â€” Part 3\n",
        "\n",
        "1. **Change the kernel** to `'linear'` or `'poly'`.  \n",
        "2. **Try 2 different `C` values** like `0.1`, `1`, and `10`. Observe what changes.\n",
        "\n",
        "### In Your Response:\n",
        "1. Whatâ€™s the tradeoff between higher and lower values of `C`?\n",
        "2. Which value of C gave you the best Accuracy?  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsK_zeHnN7iH"
      },
      "outputs": [],
      "source": [
        "# ðŸ”§ Add code here:\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Define the C values to test\n",
        "c_values = [1, 10]\n",
        "\n",
        "for c in c_values:\n",
        "    print(f\"\\n--- Training SVM with C = {c} ---\")\n",
        "    # Train SVM with the current C value\n",
        "    svm_model = SVC(kernel='linear', C=c, gamma='scale')\n",
        "    svm_model.fit(X_train_svm, y_train_svm)\n",
        "\n",
        "    # Predict\n",
        "    y_pred_svm = svm_model.predict(X_test_svm)\n",
        "\n",
        "    # Evaluate\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_svm, y_pred_svm))\n",
        "    print(\"\\nClassification Report:\\n\", classification_report(y_test_svm, y_pred_svm))\n",
        "    print(\"Accuracy:\", accuracy_score(y_test_svm, y_pred_svm))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t97OA6_od2la",
        "outputId": "3441f982-be14-43b4-a1f4-66de5d715e7a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Training SVM with C = 1 ---\n",
            "Confusion Matrix:\n",
            " [[20 18]\n",
            " [17 13]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.53      0.53        38\n",
            "           1       0.42      0.43      0.43        30\n",
            "\n",
            "    accuracy                           0.49        68\n",
            "   macro avg       0.48      0.48      0.48        68\n",
            "weighted avg       0.49      0.49      0.49        68\n",
            "\n",
            "Accuracy: 0.4852941176470588\n",
            "\n",
            "--- Training SVM with C = 10 ---\n",
            "Confusion Matrix:\n",
            " [[20 18]\n",
            " [15 15]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.53      0.55        38\n",
            "           1       0.45      0.50      0.48        30\n",
            "\n",
            "    accuracy                           0.51        68\n",
            "   macro avg       0.51      0.51      0.51        68\n",
            "weighted avg       0.52      0.51      0.52        68\n",
            "\n",
            "Accuracy: 0.5147058823529411\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyRxenDfN9HM"
      },
      "source": [
        "### âœï¸ Your Response: ðŸ”§\n",
        "1. The tradeoff between having a higher or lower C is that the higher it goes the more accurate it could get but it has a chance to overfit with the higher the C goes, and underfit the lower the C goes.\n",
        "\n",
        "2. The 10 C was slightly better than the 1 C value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VU91G9xEOAZz"
      },
      "source": [
        "## Part 4: Neural Networks\n",
        "\n",
        "### What you're going to do:\n",
        "Build a basic **feedforward neural network** to classify ad engagement.\n",
        "\n",
        "### Why this matters:\n",
        "Neural networks are the foundation of modern AI. Even a simple one can outperform traditional models when tuned correctly.\n",
        "\n",
        "### What to notice:\n",
        "- This may take several minutes to run!  Be patient.\n",
        "- How does training accuracy compare to validation accuracy?\n",
        "- Do more layers or epochs help â€” or hurt?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "SRtDeXbAOGkZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "681eceb7-153a-4a78-cbef-642bf0111054"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.4368 - loss: 0.7094 - val_accuracy: 0.5294 - val_loss: 0.6962\n",
            "Epoch 2/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4472 - loss: 0.7042 - val_accuracy: 0.5294 - val_loss: 0.6964\n",
            "Epoch 3/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5646 - loss: 0.6937 - val_accuracy: 0.5294 - val_loss: 0.6965\n",
            "Epoch 4/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5166 - loss: 0.6976 - val_accuracy: 0.4706 - val_loss: 0.6969\n",
            "Epoch 5/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5820 - loss: 0.6904 - val_accuracy: 0.4412 - val_loss: 0.6965\n",
            "Epoch 6/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5774 - loss: 0.6932 - val_accuracy: 0.4412 - val_loss: 0.6967\n",
            "Epoch 7/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6309 - loss: 0.6899 - val_accuracy: 0.4559 - val_loss: 0.6965\n",
            "Epoch 8/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6586 - loss: 0.6849 - val_accuracy: 0.4706 - val_loss: 0.6965\n",
            "Epoch 9/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5514 - loss: 0.6912 - val_accuracy: 0.4706 - val_loss: 0.6969\n",
            "Epoch 10/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6044 - loss: 0.6847 - val_accuracy: 0.5000 - val_loss: 0.6957\n",
            "Epoch 11/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6228 - loss: 0.6858 - val_accuracy: 0.5000 - val_loss: 0.6953\n",
            "Epoch 12/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6618 - loss: 0.6786 - val_accuracy: 0.5000 - val_loss: 0.6946\n",
            "Epoch 13/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6482 - loss: 0.6760 - val_accuracy: 0.5000 - val_loss: 0.6944\n",
            "Epoch 14/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6477 - loss: 0.6777 - val_accuracy: 0.5000 - val_loss: 0.6937\n",
            "Epoch 15/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6256 - loss: 0.6737 - val_accuracy: 0.5000 - val_loss: 0.6924\n",
            "Epoch 16/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6684 - loss: 0.6696 - val_accuracy: 0.5147 - val_loss: 0.6928\n",
            "Epoch 17/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6477 - loss: 0.6784 - val_accuracy: 0.5147 - val_loss: 0.6927\n",
            "Epoch 18/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6493 - loss: 0.6684 - val_accuracy: 0.5147 - val_loss: 0.6915\n",
            "Epoch 19/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7149 - loss: 0.6587 - val_accuracy: 0.5294 - val_loss: 0.6912\n",
            "Epoch 20/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6378 - loss: 0.6674 - val_accuracy: 0.5294 - val_loss: 0.6916\n",
            "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Confusion Matrix:\n",
            " [[23 15]\n",
            " [17 13]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.61      0.59        38\n",
            "           1       0.46      0.43      0.45        30\n",
            "\n",
            "    accuracy                           0.53        68\n",
            "   macro avg       0.52      0.52      0.52        68\n",
            "weighted avg       0.53      0.53      0.53        68\n",
            "\n",
            "Accuracy: 0.5294117647058824\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "# Model\n",
        "model = Sequential([\n",
        "    Dense(16, activation='relu', input_shape=(X_train_svm.shape[1],)),  #Layer 1\n",
        "    Dense(12, activation='relu'), # New Layer\n",
        "    Dense(8, activation='relu'),  #Layer 2\n",
        "    Dense(4, activation='relu'),  #Layer 3\n",
        "    Dense(1, activation='sigmoid') #Output Layer\n",
        "])\n",
        "\n",
        "# Compile\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train\n",
        "history = model.fit(X_train_svm, y_train_svm, validation_data=(X_test_svm, y_test_svm),\n",
        "                    epochs=20, batch_size=16, verbose=1)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred_nn = (model.predict(X_test_svm) > 0.5).astype(int)\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_svm, y_pred_nn))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test_svm, y_pred_nn))\n",
        "print(\"Accuracy:\", accuracy_score(y_test_svm, y_pred_nn))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "tctKhkKpOIj2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "outputId": "68fb2ac2-0a96-4b4b-9ddd-20e7be9b332e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plot learning curves\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Loss')\n",
        "plt.title('Loss Over Time')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Accuracy')\n",
        "plt.title('Accuracy Over Time')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2Xwu2LNOTWM"
      },
      "source": [
        "### ðŸ”§ Try It Yourself â€” Part 4\n",
        "\n",
        "1. Add or remove layers from the model.\n",
        "2. Increase or decrease batch size to numbers such as 8 or 32. Try out 5 different combinations of different batch sizes and layers. Notice if these changes affect ms/step for each Epoch. Also notice how the accuracy changes as you alter layers and batch size.\n",
        "3. Add Dropout to your model\n",
        "\n",
        "### In Your Response:\n",
        "1. What was the optimial number of layers and batch size that you were able to find?  (Remember, you should try about 5 different combinations)\n",
        "2. Does adding `Dropout` help reduce overfitting? Use the \"loss over time\" plot to support your answer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11lrJbJDOad-"
      },
      "outputs": [],
      "source": [
        "# ðŸ”§ Add code here"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "# Model\n",
        "model = Sequential([\n",
        "    Dense(16, activation='relu', input_shape=(X_train_svm.shape[1],)),  #Layer 1\n",
        "    Dense(12, activation='relu'), # New Layer\n",
        "    Dense(8, activation='relu'),  #Layer 2\n",
        "    Dense(4, activation='relu'),  #Layer 3\n",
        "    Dense(1, activation='sigmoid') #Output Layer\n",
        "])\n",
        "\n",
        "# Compile\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train\n",
        "history = model.fit(X_train_svm, y_train_svm, validation_data=(X_test_svm, y_test_svm),\n",
        "                    epochs=20, batch_size=16, verbose=1)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred_nn = (model.predict(X_test_svm) > 0.5).astype(int)\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_svm, y_pred_nn))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test_svm, y_pred_nn))\n",
        "print(\"Accuracy:\", accuracy_score(y_test_svm, y_pred_nn))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pCHrUldkCun",
        "outputId": "ddab7583-1995-4e49-f0eb-430e515592a3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.4654 - loss: 0.6957 - val_accuracy: 0.5735 - val_loss: 0.6769\n",
            "Epoch 2/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4517 - loss: 0.7102 - val_accuracy: 0.5735 - val_loss: 0.6821\n",
            "Epoch 3/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5442 - loss: 0.6924 - val_accuracy: 0.5882 - val_loss: 0.6825\n",
            "Epoch 4/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5535 - loss: 0.6877 - val_accuracy: 0.5735 - val_loss: 0.6822\n",
            "Epoch 5/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5054 - loss: 0.6930 - val_accuracy: 0.5588 - val_loss: 0.6826\n",
            "Epoch 6/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5103 - loss: 0.6850 - val_accuracy: 0.5294 - val_loss: 0.6833\n",
            "Epoch 7/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4940 - loss: 0.6905 - val_accuracy: 0.5294 - val_loss: 0.6830\n",
            "Epoch 8/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5593 - loss: 0.6763 - val_accuracy: 0.5441 - val_loss: 0.6836\n",
            "Epoch 9/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5632 - loss: 0.6787 - val_accuracy: 0.5294 - val_loss: 0.6827\n",
            "Epoch 10/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5090 - loss: 0.6799 - val_accuracy: 0.5294 - val_loss: 0.6824\n",
            "Epoch 11/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5610 - loss: 0.6613 - val_accuracy: 0.5441 - val_loss: 0.6816\n",
            "Epoch 12/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5487 - loss: 0.6809 - val_accuracy: 0.5441 - val_loss: 0.6817\n",
            "Epoch 13/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5479 - loss: 0.6770 - val_accuracy: 0.5441 - val_loss: 0.6819\n",
            "Epoch 14/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5726 - loss: 0.6655 - val_accuracy: 0.5441 - val_loss: 0.6812\n",
            "Epoch 15/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5389 - loss: 0.6759 - val_accuracy: 0.5441 - val_loss: 0.6827\n",
            "Epoch 16/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6373 - loss: 0.6594 - val_accuracy: 0.5441 - val_loss: 0.6852\n",
            "Epoch 17/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5593 - loss: 0.6612 - val_accuracy: 0.5147 - val_loss: 0.6904\n",
            "Epoch 18/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5905 - loss: 0.6443 - val_accuracy: 0.5441 - val_loss: 0.6916\n",
            "Epoch 19/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5639 - loss: 0.6447 - val_accuracy: 0.5588 - val_loss: 0.6950\n",
            "Epoch 20/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5809 - loss: 0.6359 - val_accuracy: 0.5441 - val_loss: 0.7021\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 7 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x78ed51cee700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\u001b[1m1/3\u001b[0m \u001b[32mâ”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 64ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x78ed51cee700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Confusion Matrix:\n",
            " [[16 22]\n",
            " [ 9 21]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.42      0.51        38\n",
            "           1       0.49      0.70      0.58        30\n",
            "\n",
            "    accuracy                           0.54        68\n",
            "   macro avg       0.56      0.56      0.54        68\n",
            "weighted avg       0.57      0.54      0.54        68\n",
            "\n",
            "Accuracy: 0.5441176470588235\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "717b7326",
        "outputId": "c105b998-1341-4c2d-f5e8-7f7be51e604a"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "# Model\n",
        "model = Sequential([\n",
        "    Dense(16, activation='relu', input_shape=(X_train_svm.shape[1],)),  #Layer 1\n",
        "    Dense(12, activation='relu'), # New Layer\n",
        "    Dense(8, activation='relu'),  #Layer 2\n",
        "    Dense(4, activation='relu'),  #Layer 3\n",
        "    Dense(1, activation='sigmoid') #Output Layer\n",
        "])\n",
        "\n",
        "# Compile\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train\n",
        "history = model.fit(X_train_svm, y_train_svm, validation_data=(X_test_svm, y_test_svm),\n",
        "                    epochs=20, batch_size=8, verbose=1)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred_nn = (model.predict(X_test_svm) > 0.5).astype(int)\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_svm, y_pred_nn))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test_svm, y_pred_nn))\n",
        "print(\"Accuracy:\", accuracy_score(y_test_svm, y_pred_nn))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - accuracy: 0.4809 - loss: 0.6907 - val_accuracy: 0.5441 - val_loss: 0.6862\n",
            "Epoch 2/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5166 - loss: 0.6950 - val_accuracy: 0.5000 - val_loss: 0.6887\n",
            "Epoch 3/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4975 - loss: 0.6899 - val_accuracy: 0.5000 - val_loss: 0.6897\n",
            "Epoch 4/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5421 - loss: 0.6867 - val_accuracy: 0.4706 - val_loss: 0.6915\n",
            "Epoch 5/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5635 - loss: 0.6795 - val_accuracy: 0.4706 - val_loss: 0.6915\n",
            "Epoch 6/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5718 - loss: 0.6814 - val_accuracy: 0.4559 - val_loss: 0.6953\n",
            "Epoch 7/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6199 - loss: 0.6785 - val_accuracy: 0.4559 - val_loss: 0.6955\n",
            "Epoch 8/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6033 - loss: 0.6788 - val_accuracy: 0.4412 - val_loss: 0.6961\n",
            "Epoch 9/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6109 - loss: 0.6677 - val_accuracy: 0.4559 - val_loss: 0.6994\n",
            "Epoch 10/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6385 - loss: 0.6656 - val_accuracy: 0.4559 - val_loss: 0.7021\n",
            "Epoch 11/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5591 - loss: 0.6678 - val_accuracy: 0.4412 - val_loss: 0.7072\n",
            "Epoch 12/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5327 - loss: 0.6618 - val_accuracy: 0.4559 - val_loss: 0.7104\n",
            "Epoch 13/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6519 - loss: 0.6540 - val_accuracy: 0.4412 - val_loss: 0.7144\n",
            "Epoch 14/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5618 - loss: 0.6696 - val_accuracy: 0.4559 - val_loss: 0.7190\n",
            "Epoch 15/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6333 - loss: 0.6477 - val_accuracy: 0.4118 - val_loss: 0.7238\n",
            "Epoch 16/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6554 - loss: 0.6219 - val_accuracy: 0.4853 - val_loss: 0.7258\n",
            "Epoch 17/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6622 - loss: 0.6234 - val_accuracy: 0.4559 - val_loss: 0.7244\n",
            "Epoch 18/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6440 - loss: 0.6529 - val_accuracy: 0.4853 - val_loss: 0.7261\n",
            "Epoch 19/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6306 - loss: 0.6534 - val_accuracy: 0.4853 - val_loss: 0.7329\n",
            "Epoch 20/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6769 - loss: 0.6222 - val_accuracy: 0.5000 - val_loss: 0.7361\n",
            "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Confusion Matrix:\n",
            " [[18 20]\n",
            " [14 16]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.47      0.51        38\n",
            "           1       0.44      0.53      0.48        30\n",
            "\n",
            "    accuracy                           0.50        68\n",
            "   macro avg       0.50      0.50      0.50        68\n",
            "weighted avg       0.51      0.50      0.50        68\n",
            "\n",
            "Accuracy: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f90dbed4",
        "outputId": "fffadfe9-4db7-4e78-c664-79b4cfa53401"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "print(\"--- Combination 2: Batch size = 32, Layers = [16, 12, 8, 4] ---\")\n",
        "# Model\n",
        "model_2 = Sequential([\n",
        "    Dense(16, activation='relu', input_shape=(X_train_svm.shape[1],)),  #Layer 1\n",
        "    Dense(12, activation='relu'), # New Layer\n",
        "    Dense(8, activation='relu'),  #Layer 2\n",
        "    Dense(4, activation='relu'),  #Layer 3\n",
        "    Dense(1, activation='sigmoid') #Output Layer\n",
        "])\n",
        "\n",
        "# Compile\n",
        "model_2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train\n",
        "history_2 = model_2.fit(X_train_svm, y_train_svm, validation_data=(X_test_svm, y_test_svm),\n",
        "                    epochs=20, batch_size=32, verbose=1)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred_nn_2 = (model_2.predict(X_test_svm) > 0.5).astype(int)\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_svm, y_pred_nn_2))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test_svm, y_pred_nn_2))\n",
        "print(\"Accuracy:\", accuracy_score(y_test_svm, y_pred_nn_2))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Combination 2: Batch size = 32, Layers = [16, 12, 8, 4] ---\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.5166 - loss: 0.6902 - val_accuracy: 0.4853 - val_loss: 0.6932\n",
            "Epoch 2/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5139 - loss: 0.6886 - val_accuracy: 0.5147 - val_loss: 0.6936\n",
            "Epoch 3/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5473 - loss: 0.6810 - val_accuracy: 0.5441 - val_loss: 0.6934\n",
            "Epoch 4/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5597 - loss: 0.6797 - val_accuracy: 0.5588 - val_loss: 0.6938\n",
            "Epoch 5/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5665 - loss: 0.6822 - val_accuracy: 0.5441 - val_loss: 0.6940\n",
            "Epoch 6/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5695 - loss: 0.6798 - val_accuracy: 0.5441 - val_loss: 0.6941\n",
            "Epoch 7/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5963 - loss: 0.6717 - val_accuracy: 0.5441 - val_loss: 0.6947\n",
            "Epoch 8/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5682 - loss: 0.6680 - val_accuracy: 0.5441 - val_loss: 0.6957\n",
            "Epoch 9/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5634 - loss: 0.6806 - val_accuracy: 0.5441 - val_loss: 0.6961\n",
            "Epoch 10/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5899 - loss: 0.6711 - val_accuracy: 0.5588 - val_loss: 0.6966\n",
            "Epoch 11/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5634 - loss: 0.6702 - val_accuracy: 0.5588 - val_loss: 0.6973\n",
            "Epoch 12/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5899 - loss: 0.6674 - val_accuracy: 0.5588 - val_loss: 0.6985\n",
            "Epoch 13/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5846 - loss: 0.6594 - val_accuracy: 0.5588 - val_loss: 0.7000\n",
            "Epoch 14/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5811 - loss: 0.6661 - val_accuracy: 0.5588 - val_loss: 0.7018\n",
            "Epoch 15/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5920 - loss: 0.6611 - val_accuracy: 0.5588 - val_loss: 0.7037\n",
            "Epoch 16/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6063 - loss: 0.6601 - val_accuracy: 0.5588 - val_loss: 0.7062\n",
            "Epoch 17/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5798 - loss: 0.6564 - val_accuracy: 0.5588 - val_loss: 0.7085\n",
            "Epoch 18/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6501 - loss: 0.6437 - val_accuracy: 0.6029 - val_loss: 0.7116\n",
            "Epoch 19/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5780 - loss: 0.6636 - val_accuracy: 0.5735 - val_loss: 0.7136\n",
            "Epoch 20/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6465 - loss: 0.6463 - val_accuracy: 0.5735 - val_loss: 0.7176\n",
            "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Confusion Matrix:\n",
            " [[14 24]\n",
            " [ 5 25]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.37      0.49        38\n",
            "           1       0.51      0.83      0.63        30\n",
            "\n",
            "    accuracy                           0.57        68\n",
            "   macro avg       0.62      0.60      0.56        68\n",
            "weighted avg       0.64      0.57      0.55        68\n",
            "\n",
            "Accuracy: 0.5735294117647058\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "print(\"--- Combination 3: Fewer Layers (2 layers: 16, 8 units), Batch size = 16 ---\")\n",
        "# Model with 2 hidden layers\n",
        "model_3 = Sequential([\n",
        "    Dense(16, activation='relu', input_shape=(X_train_svm.shape[1],)),  # Layer 1\n",
        "    Dense(8, activation='relu'),  # Layer 2\n",
        "    Dense(1, activation='sigmoid') # Output Layer\n",
        "])\n",
        "\n",
        "# Compile\n",
        "model_3.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train\n",
        "history_3 = model_3.fit(X_train_svm, y_train_svm, validation_data=(X_test_svm, y_test_svm),\n",
        "                    epochs=20, batch_size=16, verbose=1)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred_nn_3 = (model_3.predict(X_test_svm) > 0.5).astype(int)\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_svm, y_pred_nn_3))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test_svm, y_pred_nn_3))\n",
        "print(\"Accuracy:\", accuracy_score(y_test_svm, y_pred_nn_3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_stOUelosYr",
        "outputId": "f779b7d6-a501-4564-be2c-9b53778a6e55"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Combination 3: Fewer Layers (2 layers: 16, 8 units), Batch size = 16 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 105ms/step - accuracy: 0.5172 - loss: 0.6872 - val_accuracy: 0.6176 - val_loss: 0.6803\n",
            "Epoch 2/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.5227 - loss: 0.6718 - val_accuracy: 0.6176 - val_loss: 0.6817\n",
            "Epoch 3/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.5264 - loss: 0.6735 - val_accuracy: 0.6618 - val_loss: 0.6805\n",
            "Epoch 4/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.5594 - loss: 0.6780 - val_accuracy: 0.6324 - val_loss: 0.6822\n",
            "Epoch 5/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.5291 - loss: 0.6802 - val_accuracy: 0.6029 - val_loss: 0.6815\n",
            "Epoch 6/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5299 - loss: 0.6710 - val_accuracy: 0.6029 - val_loss: 0.6831\n",
            "Epoch 7/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.5447 - loss: 0.6770 - val_accuracy: 0.6029 - val_loss: 0.6849\n",
            "Epoch 8/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5658 - loss: 0.6627 - val_accuracy: 0.6029 - val_loss: 0.6840\n",
            "Epoch 9/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5726 - loss: 0.6585 - val_accuracy: 0.6029 - val_loss: 0.6837\n",
            "Epoch 10/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6016 - loss: 0.6370 - val_accuracy: 0.6029 - val_loss: 0.6839\n",
            "Epoch 11/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5464 - loss: 0.6646 - val_accuracy: 0.6029 - val_loss: 0.6854\n",
            "Epoch 12/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.4857 - loss: 0.6996 - val_accuracy: 0.6029 - val_loss: 0.6841\n",
            "Epoch 13/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5282 - loss: 0.6598 - val_accuracy: 0.6029 - val_loss: 0.6856\n",
            "Epoch 14/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6139 - loss: 0.6536 - val_accuracy: 0.6324 - val_loss: 0.6850\n",
            "Epoch 15/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5696 - loss: 0.6612 - val_accuracy: 0.6324 - val_loss: 0.6865\n",
            "Epoch 16/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6156 - loss: 0.6444 - val_accuracy: 0.6324 - val_loss: 0.6907\n",
            "Epoch 17/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6136 - loss: 0.6513 - val_accuracy: 0.6324 - val_loss: 0.6920\n",
            "Epoch 18/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5831 - loss: 0.6358 - val_accuracy: 0.6471 - val_loss: 0.6912\n",
            "Epoch 19/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6285 - loss: 0.6453 - val_accuracy: 0.6471 - val_loss: 0.6913\n",
            "Epoch 20/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6605 - loss: 0.6454 - val_accuracy: 0.6324 - val_loss: 0.6925\n",
            "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "Confusion Matrix:\n",
            " [[21 17]\n",
            " [ 8 22]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.55      0.63        38\n",
            "           1       0.56      0.73      0.64        30\n",
            "\n",
            "    accuracy                           0.63        68\n",
            "   macro avg       0.64      0.64      0.63        68\n",
            "weighted avg       0.65      0.63      0.63        68\n",
            "\n",
            "Accuracy: 0.6323529411764706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4feb1363",
        "outputId": "86c9982b-fffc-4e63-abac-981ad9641f21"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "print(\"--- Combination 4: More Layers (6 layers: 32, 24, 16, 12, 8, 4 units), Batch size = 16 ---\")\n",
        "# Model with 6 hidden layers\n",
        "model_4 = Sequential([\n",
        "    Dense(32, activation='relu', input_shape=(X_train_svm.shape[1],)),  # Layer 1\n",
        "    Dense(24, activation='relu'),  # Layer 2\n",
        "    Dense(16, activation='relu'),  # Layer 3\n",
        "    Dense(12, activation='relu'),  # Layer 4\n",
        "    Dense(8, activation='relu'),   # Layer 5\n",
        "    Dense(4, activation='relu'),   # Layer 6\n",
        "    Dense(1, activation='sigmoid')  # Output Layer\n",
        "])\n",
        "\n",
        "# Compile\n",
        "model_4.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train\n",
        "history_4 = model_4.fit(X_train_svm, y_train_svm, validation_data=(X_test_svm, y_test_svm),\n",
        "                    epochs=20, batch_size=16, verbose=1)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred_nn_4 = (model_4.predict(X_test_svm) > 0.5).astype(int)\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_svm, y_pred_nn_4))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test_svm, y_pred_nn_4))\n",
        "print(\"Accuracy:\", accuracy_score(y_test_svm, y_pred_nn_4))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Combination 4: More Layers (6 layers: 32, 24, 16, 12, 8, 4 units), Batch size = 16 ---\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.3930 - loss: 0.6944 - val_accuracy: 0.4853 - val_loss: 0.6909\n",
            "Epoch 2/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5073 - loss: 0.6918 - val_accuracy: 0.5294 - val_loss: 0.6911\n",
            "Epoch 3/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5297 - loss: 0.6918 - val_accuracy: 0.5147 - val_loss: 0.6899\n",
            "Epoch 4/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5691 - loss: 0.6905 - val_accuracy: 0.5000 - val_loss: 0.6884\n",
            "Epoch 5/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5773 - loss: 0.6904 - val_accuracy: 0.4853 - val_loss: 0.6863\n",
            "Epoch 6/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6603 - loss: 0.6811 - val_accuracy: 0.5294 - val_loss: 0.6823\n",
            "Epoch 7/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6190 - loss: 0.6825 - val_accuracy: 0.5000 - val_loss: 0.6807\n",
            "Epoch 8/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6241 - loss: 0.6850 - val_accuracy: 0.4706 - val_loss: 0.6780\n",
            "Epoch 9/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5711 - loss: 0.6789 - val_accuracy: 0.4853 - val_loss: 0.6748\n",
            "Epoch 10/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6205 - loss: 0.6724 - val_accuracy: 0.4706 - val_loss: 0.6732\n",
            "Epoch 11/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6435 - loss: 0.6706 - val_accuracy: 0.5000 - val_loss: 0.6730\n",
            "Epoch 12/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6767 - loss: 0.6441 - val_accuracy: 0.5000 - val_loss: 0.6754\n",
            "Epoch 13/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7331 - loss: 0.6370 - val_accuracy: 0.5000 - val_loss: 0.6753\n",
            "Epoch 14/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7272 - loss: 0.6488 - val_accuracy: 0.5000 - val_loss: 0.6795\n",
            "Epoch 15/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6957 - loss: 0.6348 - val_accuracy: 0.5000 - val_loss: 0.6847\n",
            "Epoch 16/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7051 - loss: 0.6428 - val_accuracy: 0.4853 - val_loss: 0.6916\n",
            "Epoch 17/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7140 - loss: 0.6333 - val_accuracy: 0.4853 - val_loss: 0.6896\n",
            "Epoch 18/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7126 - loss: 0.6204 - val_accuracy: 0.4853 - val_loss: 0.6965\n",
            "Epoch 19/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6529 - loss: 0.6458 - val_accuracy: 0.4853 - val_loss: 0.7013\n",
            "Epoch 20/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7334 - loss: 0.6000 - val_accuracy: 0.5000 - val_loss: 0.7082\n",
            "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "Confusion Matrix:\n",
            " [[21 17]\n",
            " [17 13]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.55      0.55        38\n",
            "           1       0.43      0.43      0.43        30\n",
            "\n",
            "    accuracy                           0.50        68\n",
            "   macro avg       0.49      0.49      0.49        68\n",
            "weighted avg       0.50      0.50      0.50        68\n",
            "\n",
            "Accuracy: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1fde8f4",
        "outputId": "2dcc060b-c0c9-41e4-882c-16df91936163"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "print(\"--- Combination 5 with Dropout: Fewer Layers (2 layers: 16, 8 units), Batch size = 8 ---\")\n",
        "# Model with 2 hidden layers and Dropout\n",
        "model_5 = Sequential([\n",
        "    Dense(16, activation='relu', input_shape=(X_train_svm.shape[1],)),  # Layer 1\n",
        "    Dropout(0.2), # Dropout after first hidden layer\n",
        "    Dense(8, activation='relu'),  # Layer 2\n",
        "    Dropout(0.2), # Dropout after second hidden layer\n",
        "    Dense(1, activation='sigmoid') # Output Layer\n",
        "])\n",
        "\n",
        "# Compile\n",
        "model_5.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train\n",
        "history_5 = model_5.fit(X_train_svm, y_train_svm, validation_data=(X_test_svm, y_test_svm),\n",
        "                    epochs=20, batch_size=8, verbose=1)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred_nn_5 = (model_5.predict(X_test_svm) > 0.5).astype(int)\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_svm, y_pred_nn_5))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test_svm, y_pred_nn_5))\n",
        "print(\"Accuracy: \", accuracy_score(y_test_svm, y_pred_nn_5))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Combination 5 with Dropout: Fewer Layers (2 layers: 16, 8 units), Batch size = 8 ---\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.6255 - loss: 0.6543 - val_accuracy: 0.5147 - val_loss: 0.7102\n",
            "Epoch 2/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5767 - loss: 0.6930 - val_accuracy: 0.4853 - val_loss: 0.7119\n",
            "Epoch 3/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5386 - loss: 0.7151 - val_accuracy: 0.4559 - val_loss: 0.7123\n",
            "Epoch 4/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4967 - loss: 0.7120 - val_accuracy: 0.4412 - val_loss: 0.7135\n",
            "Epoch 5/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4584 - loss: 0.7148 - val_accuracy: 0.4118 - val_loss: 0.7139\n",
            "Epoch 6/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5222 - loss: 0.6779 - val_accuracy: 0.4118 - val_loss: 0.7147\n",
            "Epoch 7/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5169 - loss: 0.6971 - val_accuracy: 0.4118 - val_loss: 0.7157\n",
            "Epoch 8/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6038 - loss: 0.6631 - val_accuracy: 0.4118 - val_loss: 0.7157\n",
            "Epoch 9/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5935 - loss: 0.6575 - val_accuracy: 0.4118 - val_loss: 0.7163\n",
            "Epoch 10/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5599 - loss: 0.6757 - val_accuracy: 0.4118 - val_loss: 0.7175\n",
            "Epoch 11/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5844 - loss: 0.6621 - val_accuracy: 0.4412 - val_loss: 0.7163\n",
            "Epoch 12/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5743 - loss: 0.6936 - val_accuracy: 0.4559 - val_loss: 0.7166\n",
            "Epoch 13/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5311 - loss: 0.6841 - val_accuracy: 0.4559 - val_loss: 0.7154\n",
            "Epoch 14/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5193 - loss: 0.6799 - val_accuracy: 0.4559 - val_loss: 0.7155\n",
            "Epoch 15/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5753 - loss: 0.6662 - val_accuracy: 0.4412 - val_loss: 0.7185\n",
            "Epoch 16/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5887 - loss: 0.6618 - val_accuracy: 0.4412 - val_loss: 0.7216\n",
            "Epoch 17/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6034 - loss: 0.6594 - val_accuracy: 0.4559 - val_loss: 0.7208\n",
            "Epoch 18/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6331 - loss: 0.6657 - val_accuracy: 0.4559 - val_loss: 0.7215\n",
            "Epoch 19/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5365 - loss: 0.6678 - val_accuracy: 0.4559 - val_loss: 0.7227\n",
            "Epoch 20/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6254 - loss: 0.6630 - val_accuracy: 0.4559 - val_loss: 0.7224\n",
            "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Confusion Matrix:\n",
            " [[14 24]\n",
            " [13 17]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.37      0.43        38\n",
            "           1       0.41      0.57      0.48        30\n",
            "\n",
            "    accuracy                           0.46        68\n",
            "   macro avg       0.47      0.47      0.45        68\n",
            "weighted avg       0.47      0.46      0.45        68\n",
            "\n",
            "Accuracy:  0.45588235294117646\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7FnRfAFOcd5"
      },
      "source": [
        "### âœï¸ Your Response: ðŸ”§\n",
        "1. Having 2 layers with 16 batches was the optimal for the accuracy of the model.\n",
        "\n",
        "2. Dropout in fact did not help the model neither did anything benefical to the fitting of the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9mvbHXCOeFt"
      },
      "source": [
        "## ðŸ”§ Part 5: Reflection (100 words or less per question)\n",
        "\n",
        "1. Which model performed best on your dataset? Is this the result you expected?\n",
        "2. Did any of the models appear to be overfit or underfit? How could you tell?\n",
        "3. Which model would you recommend to a marketing team and why?\n",
        "\n",
        "You can use the accuracy scores, confusion matrices, and training graphs to support your conclusions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kx-ZDdpOisb"
      },
      "source": [
        "### âœï¸ Your Response: ðŸ”§\n",
        "1. My third neural network model perforrmed best on the dataset. It was not the result because of the underwhelming accuracy on the model.\n",
        "\n",
        "2. Most of them seemed to be underfit because of the accuracy of the models being so low.\n",
        "\n",
        "3. If I had to, I would recommend my third neural network model, although it needs some work. Because of the accuracy percentage and they could improve upon it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3xMWPnS0RsO"
      },
      "source": [
        "## Export Your Notebook to Submit in Canvas\n",
        "- Use the instructions from Lab 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogF6y85L0RsP"
      },
      "outputs": [],
      "source": [
        "!jupyter nbconvert --to html \"lab_12_LastnameFirstname.ipynb\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}